#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDFæ–‡æ¡£å¤„ç†æ¨¡å—
ç”¨äºä¸Šä¼ PDFæ–‡ä»¶å¹¶é€šè¿‡LLMç”Ÿæˆè§£è¯»æ–‡ç« 
"""

import os
import json
import hashlib
import time
from datetime import datetime
from pathlib import Path
import PyPDF2
import requests
from werkzeug.utils import secure_filename
from openai import OpenAI

class PDFProcessor:
    def __init__(self):
        # åˆ›å»ºä¸Šä¼ ç›®å½•
        self.upload_dir = 'uploads'
        self.pdf_dir = os.path.join(self.upload_dir, 'pdf')
        self.articles_dir = os.path.join(self.upload_dir, 'articles')
        
        for dir_path in [self.upload_dir, self.pdf_dir, self.articles_dir]:
            os.makedirs(dir_path, exist_ok=True)
        
        # åˆå§‹åŒ–ç«å±±æ–¹èˆŸå®¢æˆ·ç«¯
        self.client = OpenAI(
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            api_key=os.environ.get("ARK_API_KEY", "86b2b17f-8b5a-4cde-ba7a-b9bd3ec93da3"),
        )
        self.model = "doubao-seed-1-6-thinking-250715"
    
    def allowed_file(self, filename):
        """æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦å…è®¸"""
        ALLOWED_EXTENSIONS = {'pdf'}
        return '.' in filename and \
               filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS
    
    def save_pdf(self, file):
        """ä¿å­˜PDFæ–‡ä»¶"""
        if not self.allowed_file(file.filename):
            return None, "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè¯·ä¸Šä¼ PDFæ–‡ä»¶"
        
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        filename = secure_filename(file.filename)
        timestamp = int(time.time())
        name, ext = os.path.splitext(filename)
        
        # åˆ›å»ºå”¯ä¸€æ–‡ä»¶å
        unique_filename = f"{name}_{timestamp}{ext}"
        file_path = os.path.join(self.pdf_dir, unique_filename)
        
        try:
            file.save(file_path)
            return file_path, None
        except Exception as e:
            return None, f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}"
    
    def extract_text_from_pdf(self, pdf_path):
        """ä»PDFä¸­æå–æ–‡æœ¬"""
        try:
            text = ""
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                
                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    text += page.extract_text() + "\n"
            
            return text.strip(), None
        except Exception as e:
            return None, f"æå–PDFæ–‡æœ¬å¤±è´¥: {str(e)}"
    
    def extract_paper_title(self, text):
        """ä»PDFæ–‡æœ¬ä¸­æå–è®ºæ–‡æ ‡é¢˜"""
        try:
            # æ„å»ºæå–æ ‡é¢˜çš„æç¤ºè¯
            title_prompt = f"""
è¯·ä»ä»¥ä¸‹PDFæ–‡æ¡£å†…å®¹ä¸­æå–è®ºæ–‡çš„çœŸå®æ ‡é¢˜ã€‚

PDFå†…å®¹ï¼ˆå‰2000å­—ç¬¦ï¼‰ï¼š
{text[:2000]}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼š
1. è‹±æ–‡æ ‡é¢˜ï¼š[æå–çš„è‹±æ–‡æ ‡é¢˜]
2. ä¸­æ–‡æ ‡é¢˜ï¼š[æä¾›å‡†ç¡®çš„ä¸­æ–‡ç¿»è¯‘]

è¦æ±‚ï¼š
- æå–æ–‡æ¡£å¼€å¤´éƒ¨åˆ†çš„æ ‡é¢˜ï¼Œé€šå¸¸æ˜¯è®ºæ–‡çš„æ­£å¼æ ‡é¢˜
- ä¸­æ–‡ç¿»è¯‘è¦å‡†ç¡®ã€ä¸“ä¸š
- å¦‚æœæ‰¾ä¸åˆ°æ˜ç¡®çš„æ ‡é¢˜ï¼Œè¯·è¿”å›"è®ºæ–‡è§£è¯»"
"""
            
            # è°ƒç”¨APIæå–æ ‡é¢˜
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯æ–‡æ¡£åˆ†æå¸ˆï¼Œæ“…é•¿æå–è®ºæ–‡æ ‡é¢˜å¹¶æä¾›å‡†ç¡®çš„ä¸­æ–‡ç¿»è¯‘ã€‚"},
                    {"role": "user", "content": title_prompt}
                ],
                temperature=0.3
            )
            
            title_content = response.choices[0].message.content.strip()
            
            # è§£æè¿”å›çš„æ ‡é¢˜
            lines = title_content.split('\n')
            english_title = "è®ºæ–‡è§£è¯»"
            chinese_title = "è®ºæ–‡è§£è¯»"
            
            for line in lines:
                if line.startswith('1. è‹±æ–‡æ ‡é¢˜ï¼š'):
                    english_title = line.replace('1. è‹±æ–‡æ ‡é¢˜ï¼š', '').strip()
                elif line.startswith('2. ä¸­æ–‡æ ‡é¢˜ï¼š'):
                    chinese_title = line.replace('2. ä¸­æ–‡æ ‡é¢˜ï¼š', '').strip()
            
            return english_title, chinese_title
            
        except Exception as e:
            print(f"æå–æ ‡é¢˜å¤±è´¥: {str(e)}")
            return "è®ºæ–‡è§£è¯»", "è®ºæ–‡è§£è¯»"

    def call_llm_api(self, text, title="è®ºæ–‡è§£è¯»", download_link=None):
        """è°ƒç”¨ç«å±±æ–¹èˆŸLLM APIç”Ÿæˆè§£è¯»æ–‡ç« """
        try:
            # å…ˆæå–è®ºæ–‡æ ‡é¢˜
            english_title, chinese_title = self.extract_paper_title(text)
            
            # æ„å»ºå®Œæ•´çš„æ ‡é¢˜ï¼ˆä¸­è‹±åŒè¯­ï¼‰
            full_title = f"{chinese_title} | {english_title}"
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""
è¯·å¯¹ä»¥ä¸‹PDFæ–‡æ¡£å†…å®¹è¿›è¡Œä¸“ä¸šè§£è¯»ï¼Œç”Ÿæˆä¸€ç¯‡ç»“æ„åŒ–çš„è§£è¯»æ–‡ç« ã€‚

è®ºæ–‡æ ‡é¢˜ï¼š{full_title}
è‹±æ–‡æ ‡é¢˜ï¼š{english_title}
ä¸­æ–‡æ ‡é¢˜ï¼š{chinese_title}

æ–‡æ¡£å†…å®¹ï¼š
{text[:8000]}  # é™åˆ¶æ–‡æœ¬é•¿åº¦é¿å…è¶…å‡ºAPIé™åˆ¶

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆè§£è¯»æ–‡ç« ï¼Œä½¿ç”¨æ¸…æ™°çš„HTMLç»“æ„å’Œæ ·å¼ï¼š

<div class="document-overview">
<h2>ğŸ“„ æ–‡æ¡£æ¦‚è¿°</h2>
<p>ç®€è¦æ¦‚è¿°æ–‡æ¡£çš„ä¸»è¦å†…å®¹å’Œæ ¸å¿ƒè§‚ç‚¹</p>
</div>

<div class="deep-analysis">
<h2>ğŸ” æ·±åº¦åˆ†æ</h2>
<h3>1. é—®é¢˜èƒŒæ™¯</h3>
<p>åˆ†ææ–‡æ¡£è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜</p>

<h3>2. æ ¸å¿ƒè§£å†³æ–¹æ¡ˆ</h3>
<p>è¯¦ç»†é˜è¿°ä¸»è¦è§£å†³æ–¹æ¡ˆ</p>

<h3>3. å®éªŒéªŒè¯</h3>
<p>åˆ†æå®éªŒè®¾è®¡å’ŒéªŒè¯ç»“æœ</p>
</div>

<div class="key-points">
<h2>ğŸ“‹ æ ¸å¿ƒè¦ç‚¹</h2>
<ul>
<li>è¦ç‚¹1ï¼šç®€æ´æ˜äº†çš„æè¿°</li>
<li>è¦ç‚¹2ï¼šç®€æ´æ˜äº†çš„æè¿°</li>
<li>è¦ç‚¹3ï¼šç®€æ´æ˜äº†çš„æè¿°</li>
<li>è¦ç‚¹4ï¼šç®€æ´æ˜äº†çš„æè¿°</li>
<li>è¦ç‚¹5ï¼šç®€æ´æ˜äº†çš„æè¿°</li>
</ul>
</div>

<div class="summary-recommendations">
<h2>ğŸ’¡ æ€»ç»“ä¸å»ºè®®</h2>
<p>åŸºäºæ–‡æ¡£å†…å®¹ï¼Œæä¾›å®ç”¨çš„æ€»ç»“å’Œå»ºè®®</p>
</div>

<div class="key-insights">
<h2>ğŸ¯ å…³é”®æ´å¯Ÿ</h2>
<p>ä»æ–‡æ¡£ä¸­æç‚¼å‡ºçš„ç‹¬ç‰¹è§è§£å’Œå¯å‘</p>
</div>

<div class="application-guidance">
<h2>ğŸš€ åº”ç”¨è½åœ°æŒ‡å¯¼</h2>
<h3>1. ä¸»è¦åº”ç”¨åœºæ™¯</h3>
<p>åˆ†æè¯¥æŠ€æœ¯æœ€é€‚åˆçš„åº”ç”¨é¢†åŸŸå’Œå…·ä½“åœºæ™¯</p>

<h3>2. å®æ–½å»ºè®®</h3>
<p>æä¾›æŠ€æœ¯è½åœ°çš„å…·ä½“å»ºè®®å’Œæ³¨æ„äº‹é¡¹</p>

<h3>3. å•†ä¸šä»·å€¼</h3>
<p>åˆ†ææŠ€æœ¯å¸¦æ¥çš„å•†ä¸šä»·å€¼å’Œç«äº‰ä¼˜åŠ¿</p>

<h3>4. æŠ€æœ¯é—¨æ§›</h3>
<p>è¯„ä¼°å®æ–½è¯¥æŠ€æœ¯æ‰€éœ€çš„æŠ€æœ¯æ¡ä»¶å’Œèµ„æºè¦æ±‚</p>
</div>

è¦æ±‚ï¼š
1. ä½¿ç”¨æ¸…æ™°çš„HTMLç»“æ„ï¼Œæ¯ä¸ªéƒ¨åˆ†ç”¨divåŒ…è£…
2. æ ‡é¢˜ä½¿ç”¨h2ã€h3æ ‡ç­¾
3. æ®µè½ä½¿ç”¨pæ ‡ç­¾
4. åˆ—è¡¨ä½¿ç”¨ulå’Œliæ ‡ç­¾
5. é‡è¦å†…å®¹ç”¨<strong>æ ‡ç­¾åŠ ç²—
6. è¯­è¨€è¦ä¸“ä¸šã€å‡†ç¡®ã€æ˜“è¯»
7. æ¯ä¸ªæ®µè½ä¸è¦å¤ªé•¿ï¼Œä¿æŒå¯è¯»æ€§
8. åº”ç”¨è½åœ°æŒ‡å¯¼éƒ¨åˆ†è¦ç»“åˆå…·ä½“è¡Œä¸šå’Œåœºæ™¯ï¼Œæä¾›å®ç”¨çš„å»ºè®®
"""
            
            # è°ƒç”¨ç«å±±æ–¹èˆŸAPI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=4000,
                temperature=0.7
            )
            
            # è·å–ç”Ÿæˆçš„å†…å®¹
            llm_content = response.choices[0].message.content
            
            # æ·»åŠ ä¸‹è½½é“¾æ¥éƒ¨åˆ†
            download_href = download_link if download_link else "#"
            download_text = "ä¸‹è½½PDFæ–‡æ¡£" if download_link else "PDFæ–‡æ¡£å·²ä¸Šä¼ "
            
            content = llm_content + f"""
            
            <div class="download-section" style="margin-top: 30px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                <h3>ğŸ“¥ åŸå§‹æ–‡æ¡£ä¸‹è½½</h3>
                <p>å¦‚éœ€æŸ¥çœ‹å®Œæ•´å†…å®¹ï¼Œè¯·ä¸‹è½½åŸå§‹PDFæ–‡æ¡£ï¼š</p>
                <a href="{download_href}" class="download-link" style="display: inline-block; padding: 10px 20px; background: #007bff; color: white; text-decoration: none; border-radius: 5px;" {"target='_blank'" if download_link else ""}>{download_text}</a>
            </div>
            """
            
            return content, None
            
        except Exception as e:
            print(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            return self.generate_fallback_content(text, title)
    
    def generate_fallback_content(self, text, title):
        """å½“LLM APIå¤±è´¥æ—¶ç”Ÿæˆå¤‡ç”¨å†…å®¹"""
        summary = self.generate_summary(text)
        analysis = self.generate_analysis(text)
        key_points = self.extract_key_points(text)
        
        content = f"""
        <h2>ğŸ“„ æ–‡æ¡£æ¦‚è¿°</h2>
        <p>{summary}</p>
        
        <h2>ğŸ” æ·±åº¦åˆ†æ</h2>
        <p>{analysis}</p>
        
        <h2>ğŸ“‹ æ ¸å¿ƒè¦ç‚¹</h2>
        <ul>
            {''.join([f'<li>{point}</li>' for point in key_points])}
        </ul>
        
        <h2>ğŸ’¡ æ€»ç»“ä¸å»ºè®®</h2>
        <p>æœ¬æ–‡æ¡£å†…å®¹ä¸°å¯Œï¼Œæ¶µç›–äº†å¤šä¸ªé‡è¦æ–¹é¢ã€‚å»ºè®®è¯»è€…é‡ç‚¹å…³æ³¨æ ¸å¿ƒè¦ç‚¹éƒ¨åˆ†ï¼Œå¹¶ç»“åˆå®é™…æƒ…å†µè¿›è¡Œåº”ç”¨ã€‚</p>
        
        <div class="download-section" style="margin-top: 30px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
            <h3>ğŸ“¥ åŸå§‹æ–‡æ¡£ä¸‹è½½</h3>
            <p>å¦‚éœ€æŸ¥çœ‹å®Œæ•´å†…å®¹ï¼Œè¯·ä¸‹è½½åŸå§‹PDFæ–‡æ¡£ï¼š</p>
            <a href="#" class="download-link" style="display: inline-block; padding: 10px 20px; background: #007bff; color: white; text-decoration: none; border-radius: 5px;">ä¸‹è½½PDFæ–‡æ¡£</a>
        </div>
        """
        
        return content, None
    
    def generate_summary(self, text):
        """ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"""
        # ç®€å•çš„æ‘˜è¦ç”Ÿæˆé€»è¾‘
        sentences = text.split('ã€‚')
        if len(sentences) > 3:
            summary = 'ã€‚'.join(sentences[:3]) + 'ã€‚'
        else:
            summary = text[:200] + "..." if len(text) > 200 else text
        
        return summary
    
    def generate_analysis(self, text):
        """ç”Ÿæˆåˆ†æå†…å®¹"""
        # ç®€å•çš„åˆ†æç”Ÿæˆé€»è¾‘
        word_count = len(text)
        sentence_count = len(text.split('ã€‚'))
        
        analysis = f"""
        æœ¬æ–‡æ¡£å…±åŒ…å«çº¦{word_count}ä¸ªå­—ç¬¦ï¼Œ{sentence_count}ä¸ªå¥å­ã€‚
        æ–‡æ¡£å†…å®¹ç»“æ„æ¸…æ™°ï¼Œä¿¡æ¯å¯†åº¦è¾ƒé«˜ï¼Œé€‚åˆè¿›è¡Œæ·±å…¥å­¦ä¹ å’Œç ”ç©¶ã€‚
        å»ºè®®è¯»è€…æŒ‰ç…§ç« èŠ‚é¡ºåºé˜…è¯»ï¼Œé‡ç‚¹å…³æ³¨æ ¸å¿ƒæ¦‚å¿µå’Œå…³é”®æ•°æ®ã€‚
        """
        
        return analysis.strip()
    
    def extract_key_points(self, text):
        """æå–å…³é”®è¦ç‚¹"""
        # ç®€å•çš„å…³é”®ç‚¹æå–é€»è¾‘
        sentences = text.split('ã€‚')
        key_points = []
        
        for sentence in sentences[:10]:  # å–å‰10ä¸ªå¥å­ä½œä¸ºå…³é”®ç‚¹
            if len(sentence.strip()) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                key_points.append(sentence.strip())
        
        return key_points[:5]  # è¿”å›å‰5ä¸ªå…³é”®ç‚¹
    
    def create_article_from_pdf(self, pdf_path, custom_title=None, custom_tags=None, download_link=None):
        """ä»PDFåˆ›å»ºæ–‡ç« """
        try:
            # æå–PDFæ–‡æœ¬
            text, error = self.extract_text_from_pdf(pdf_path)
            if error:
                return None, error
            
            # è°ƒç”¨LLMç”Ÿæˆè§£è¯»å†…å®¹
            content, error = self.call_llm_api(text, custom_title, download_link)
            if error:
                return None, error
            
            # ç”Ÿæˆæ–‡ç« ID
            pdf_name = os.path.basename(pdf_path)
            article_id = f"pdf-{hashlib.md5(pdf_name.encode()).hexdigest()[:12]}"
            
            # æå–çœŸå®çš„è®ºæ–‡æ ‡é¢˜ï¼ˆä¸­è‹±åŒè¯­ï¼‰
            if not custom_title:  # åªæœ‰åœ¨æ²¡æœ‰è‡ªå®šä¹‰æ ‡é¢˜æ—¶æ‰æå–è®ºæ–‡æ ‡é¢˜
                english_title, chinese_title = self.extract_paper_title(text)
                title = f"{chinese_title} | {english_title}"
            else:
                title = custom_title
            
            # ç”Ÿæˆæ ‡ç­¾
            tags = custom_tags or ["AIæŠ€æœ¯ç¯‡ç« ", "è®ºæ–‡è§£è¯»", "æ–‡æ¡£åˆ†æ", "AIè§£è¯»"]
            if isinstance(tags, str):
                tags = [tag.strip() for tag in tags.split(',') if tag.strip()]
            
            # ç”Ÿæˆæ‘˜è¦
            summary = self.generate_summary(text)
            
            # åˆ›å»ºæ–‡ç« æ•°æ®
            article_data = {
                'id': article_id,
                'title': title,
                'source': 'è®ºæ–‡è§£è¯»',
                'summary': summary,
                'url': download_link or f"/uploads/pdf/{os.path.basename(pdf_path)}",  # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰ä¸‹è½½é“¾æ¥
                'date': datetime.now().strftime('%Y-%m-%d'),
                'tags': tags,
                'content': content,
                'pdf_path': pdf_path,  # ä¿å­˜PDFè·¯å¾„ç”¨äºä¸‹è½½
                'original_filename': os.path.basename(pdf_path),
                'download_link': download_link  # ä¿å­˜è‡ªå®šä¹‰ä¸‹è½½é“¾æ¥
            }
            
            # ç”ŸæˆHTMLæ–‡ä»¶
            html_path = f"articles/{article_id}.html"
            self.generate_html_file(article_data, html_path)
            
            return article_data, None
            
        except Exception as e:
            return None, f"åˆ›å»ºæ–‡ç« å¤±è´¥: {str(e)}"
    
    def generate_html_file(self, article_data, html_path):
        """ç”Ÿæˆæ–‡ç« HTMLæ–‡ä»¶"""
        try:
            # æ„å»ºHTMLå†…å®¹ - ä½¿ç”¨å¤–éƒ¨CSSæ ·å¼
            html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{article_data['title']} | äº‘ç§’æ­AIå‘¨æŠ¥</title>
    <meta name="description" content="{article_data['title']} - äº‘ç§’æ­AIå‘¨æŠ¥">
    <link rel="stylesheet" href="../styles.css">
    <link rel="icon" type="image/png" href="../favicon.png">
    <link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&display=swap" rel="stylesheet">
</head>
<body>
    <div class="pixel-bg"></div>
    
    <div class="pdf-article-container">
        <header class="pdf-article-header">
            <h1 class="pdf-article-title">{article_data['title']}</h1>
            <div class="pdf-article-meta">
                <span>ğŸ“° {article_data['source']}</span>
                <span>ğŸ“… {article_data['date']}</span>
            </div>
            <div class="pdf-article-tags">
                {''.join([f'<span class="pixel-tag">{tag}</span>' for tag in article_data['tags']])}
            </div>
        </header>
        
        <main class="pdf-article-content">
            {article_data['content']}
        </main>
        
        <div class="pdf-article-actions">
            <a href="../index.html" class="pdf-action-btn">ğŸ  è¿”å›é¦–é¡µ</a>
            <a href="{article_data['url']}" class="pdf-action-btn" target="_blank">ğŸ“¥ ä¸‹è½½PDFæ–‡æ¡£</a>
        </div>
    </div>
</body>
</html>"""
            
            # ç¡®ä¿articlesç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(html_path), exist_ok=True)
            
            # å†™å…¥HTMLæ–‡ä»¶
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            print(f"âœ… ç”Ÿæˆäº†HTMLæ–‡ä»¶: {html_path}")
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆHTMLæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def update_articles_json(self, new_article):
        """æ›´æ–°articles.jsonæ–‡ä»¶"""
        try:
            json_file = 'posts/articles.json'
            
            # è¯»å–ç°æœ‰æ–‡ç« 
            if os.path.exists(json_file):
                with open(json_file, 'r', encoding='utf-8') as f:
                    articles = json.load(f)
            else:
                articles = []
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„æ–‡ç« 
            existing_ids = [article.get('id') for article in articles]
            if new_article['id'] in existing_ids:
                # æ›´æ–°ç°æœ‰æ–‡ç« 
                for i, article in enumerate(articles):
                    if article.get('id') == new_article['id']:
                        articles[i] = new_article
                        print(f"âœ… æ›´æ–°äº†ç°æœ‰æ–‡ç« : {new_article['title']}")
                        break
            else:
                # æ·»åŠ æ–°æ–‡ç« åˆ°å¼€å¤´
                articles.insert(0, new_article)
                print(f"âœ… æ·»åŠ äº†æ–°æ–‡ç« : {new_article['title']}")
            
            # ä¿å­˜æ–‡ä»¶
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(articles, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“ å·²æ›´æ–° {json_file}")
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°JSONæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def generate_weekly_report(self, articles_data, progress_callback=None):
        """ç”Ÿæˆå‘¨æŠ¥"""
        try:
            if progress_callback:
                progress_callback(55, 'æ­£åœ¨å‡†å¤‡å‘¨æŠ¥æ•°æ®...', 'æ„å»ºæç¤ºè¯')
            # æ„å»ºå‘¨æŠ¥æç¤ºè¯
            articles_summary = []
            for article in articles_data[:10]:  # å–æœ€è¿‘10ç¯‡æ–‡ç« 
                articles_summary.append(f"""
æ ‡é¢˜ï¼š{article.get('title', 'æœªçŸ¥æ ‡é¢˜')}
æ¥æºï¼š{article.get('source', 'æœªçŸ¥æ¥æº')}
æ—¥æœŸï¼š{article.get('date', 'æœªçŸ¥æ—¥æœŸ')}
æ‘˜è¦ï¼š{article.get('summary', 'æ— æ‘˜è¦')[:200]}
""")
            
            articles_text = "\n".join(articles_summary)
            
            if progress_callback:
                progress_callback(60, 'æ­£åœ¨æ„å»ºå‘¨æŠ¥ç»“æ„...', 'å‡†å¤‡AIæç¤ºè¯')
            
            # æ„å»ºæ¨èé˜…è¯»çš„æ–‡ç« åˆ—è¡¨ï¼ˆç”¨äºAIç”Ÿæˆé“¾æ¥ï¼‰
            recommended_articles = []
            for article in articles_data[:5]:  # å–å‰5ç¯‡æ–‡ç« ä½œä¸ºæ¨è
                recommended_articles.append({
                    'title': article.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                    'id': article.get('id', ''),
                    'source': article.get('source', 'æœªçŸ¥æ¥æº'),
                    'date': article.get('date', 'æœªçŸ¥æ—¥æœŸ')
                })
            
            recommended_articles_text = "\n".join([
                f"- {art['title']} ({art['source']}, {art['date']})" 
                for art in recommended_articles
            ])
            
            prompt = f"""
è¯·åŸºäºä»¥ä¸‹AIç›¸å…³æ–‡ç« å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„AIå‘¨æŠ¥ã€‚

æ–‡ç« åˆ—è¡¨ï¼š
{articles_text}

æ¨èé˜…è¯»æ–‡ç« åˆ—è¡¨ï¼š
{recommended_articles_text}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆå‘¨æŠ¥ï¼Œä½¿ç”¨æ¸…æ™°çš„HTMLç»“æ„å’Œæ ·å¼ï¼š

<div class="weekly-report-header">
<h1>ğŸ¤– AIå‘¨æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆç¬¬%Uå‘¨')}</h1>
<p class="report-subtitle">AIå‘¨æŠ¥è¶‹åŠ¿åˆ†æè¡Œä¸šåŠ¨æ€è‡ªåŠ¨ç”Ÿæˆ</p>
</div>

<div class="weekly-overview">
<h2>ğŸ“Š æœ¬å‘¨æ¦‚è§ˆ</h2>
<p>ç®€è¦æ¦‚è¿°æœ¬å‘¨AIé¢†åŸŸçš„ä¸»è¦åŠ¨æ€å’Œè¶‹åŠ¿ï¼Œçªå‡ºæ ¸å¿ƒç‰¹å¾å’Œå…³é”®å˜åŒ–</p>
</div>

<div class="hot-topics">
<h2>ğŸ”¥ çƒ­é—¨è¯é¢˜</h2>
<p>æ€»ç»“æœ¬å‘¨æœ€å—å…³æ³¨çš„AIè¯é¢˜å’Œè®¨è®ºçƒ­ç‚¹ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>è¯é¢˜1</strong>ï¼šè¯¦ç»†æè¿°å’Œå½±å“åˆ†æ</li>
<li><strong>è¯é¢˜2</strong>ï¼šè¯¦ç»†æè¿°å’Œå½±å“åˆ†æ</li>
<li><strong>è¯é¢˜3</strong>ï¼šè¯¦ç»†æè¿°å’Œå½±å“åˆ†æ</li>
</ul>
</div>

<div class="key-breakthroughs">
<h2>ğŸ’¡ é‡è¦çªç ´</h2>
<p>åˆ—ä¸¾æœ¬å‘¨AIæŠ€æœ¯çš„é‡è¦çªç ´å’Œåˆ›æ–°ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>çªç ´1</strong>ï¼šæŠ€æœ¯ç»†èŠ‚å’Œæ„ä¹‰</li>
<li><strong>çªç ´2</strong>ï¼šæŠ€æœ¯ç»†èŠ‚å’Œæ„ä¹‰</li>
<li><strong>çªç ´3</strong>ï¼šæŠ€æœ¯ç»†èŠ‚å’Œæ„ä¹‰</li>
</ul>
</div>

<div class="industry-trends">
<h2>ğŸ“ˆ è¡Œä¸šåŠ¨æ€</h2>
<p>åˆ†æAIè¡Œä¸šçš„é‡è¦åŠ¨æ€å’Œå‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>åŠ¨æ€1</strong>ï¼šå…¬å¸/äº§å“åŠ¨æ€å’Œå½±å“</li>
<li><strong>åŠ¨æ€2</strong>ï¼šå…¬å¸/äº§å“åŠ¨æ€å’Œå½±å“</li>
<li><strong>åŠ¨æ€3</strong>ï¼šå…¬å¸/äº§å“åŠ¨æ€å’Œå½±å“</li>
</ul>
</div>

<div class="deep-analysis">
<h2>ğŸ¯ æ·±åº¦è§£è¯»</h2>
<h3>1. é‡è¦æŠ€æœ¯è§£è¯»</h3>
<p>é€‰æ‹©1-2ä¸ªé‡è¦æŠ€æœ¯æˆ–äº§å“è¿›è¡Œæ·±åº¦åˆ†æï¼ŒåŒ…æ‹¬æŠ€æœ¯åŸç†ã€åº”ç”¨åœºæ™¯ã€å¸‚åœºå½±å“ç­‰</p>

<h3>2. è¡Œä¸šè¶‹åŠ¿è§£è¯»</h3>
<p>åˆ†æè¡Œä¸šå‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬ç«äº‰æ ¼å±€ã€å•†ä¸šæ¨¡å¼ã€ç”¨æˆ·éœ€æ±‚å˜åŒ–ç­‰</p>
</div>

<div class="trend-outlook">
<h2>ğŸ”® è¶‹åŠ¿å±•æœ›</h2>
<p>åŸºäºæœ¬å‘¨åŠ¨æ€ï¼Œé¢„æµ‹æœªæ¥AIå‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>è¶‹åŠ¿1</strong>ï¼šå‘å±•æ–¹å‘å’Œé¢„æœŸå½±å“</li>
<li><strong>è¶‹åŠ¿2</strong>ï¼šå‘å±•æ–¹å‘å’Œé¢„æœŸå½±å“</li>
<li><strong>è¶‹åŠ¿3</strong>ï¼šå‘å±•æ–¹å‘å’Œé¢„æœŸå½±å“</li>
</ul>
</div>

<div class="recommended-reading">
<h2>ğŸ“š æ¨èé˜…è¯»</h2>
<p>æ¨èæœ¬å‘¨å€¼å¾—æ·±å…¥é˜…è¯»çš„æ–‡ç« ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li><strong><a href="æ–‡ç« é“¾æ¥">æ–‡ç« æ ‡é¢˜</a></strong>ï¼šæ¨èç†ç”±</li>
<li><strong><a href="æ–‡ç« é“¾æ¥">æ–‡ç« æ ‡é¢˜</a></strong>ï¼šæ¨èç†ç”±</li>
<li><strong><a href="æ–‡ç« é“¾æ¥">æ–‡ç« æ ‡é¢˜</a></strong>ï¼šæ¨èç†ç”±</li>
</ul>
</div>

è¦æ±‚ï¼š
1. ä½¿ç”¨æ¸…æ™°çš„HTMLç»“æ„ï¼Œæ¯ä¸ªéƒ¨åˆ†ç”¨divåŒ…è£…
2. æ ‡é¢˜ä½¿ç”¨h1ã€h2ã€h3æ ‡ç­¾
3. æ®µè½ä½¿ç”¨pæ ‡ç­¾
4. åˆ—è¡¨ä½¿ç”¨ulå’Œliæ ‡ç­¾
5. é‡è¦å†…å®¹ç”¨<strong>æ ‡ç­¾åŠ ç²—
6. è¯­è¨€è¦ä¸“ä¸šã€å‡†ç¡®ã€æœ‰æ´å¯ŸåŠ›
7. æ¯ä¸ªæ®µè½ä¸è¦å¤ªé•¿ï¼Œä¿æŒå¯è¯»æ€§
8. å†…å®¹è¦åŸºäºæä¾›çš„æ–‡ç« æ•°æ®ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
9. ä¿æŒå®¢è§‚ä¸­ç«‹çš„åˆ†æè§†è§’
10. åœ¨æ¨èé˜…è¯»éƒ¨åˆ†ï¼Œè¯·ä»æä¾›çš„æ¨èé˜…è¯»æ–‡ç« åˆ—è¡¨ä¸­é€‰æ‹©3-5ç¯‡æœ€ç›¸å…³çš„æ–‡ç« 
11. æ¨èé˜…è¯»çš„é“¾æ¥æ ¼å¼ä¸ºï¼š<a href="../articles/æ–‡ç« ID.html">æ–‡ç« æ ‡é¢˜</a>
12. æ¨èç†ç”±è¦å…·ä½“ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆå€¼å¾—é˜…è¯»
"""
            
            if progress_callback:
                progress_callback(70, 'æ­£åœ¨è°ƒç”¨AIç”Ÿæˆå‘¨æŠ¥...', 'å‘é€è¯·æ±‚åˆ°AIæœåŠ¡')
            
            # è°ƒç”¨ç«å±±æ–¹èˆŸAPI
            try:
                if progress_callback:
                    progress_callback(75, 'æ­£åœ¨è°ƒç”¨AIæœåŠ¡...', 'ç­‰å¾…AIå“åº”')
                
                print(f"å¼€å§‹è°ƒç”¨AI APIç”Ÿæˆå‘¨æŠ¥...")
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=4000,
                    temperature=0.7
                )
                
                print(f"AI APIè°ƒç”¨æˆåŠŸ!")
                
                if progress_callback:
                    progress_callback(85, 'æ­£åœ¨å¤„ç†AIå“åº”...', 'è§£æç”Ÿæˆçš„å†…å®¹')
                
                # è·å–ç”Ÿæˆçš„å†…å®¹
                report_content = response.choices[0].message.content
                print(f"AIç”Ÿæˆå†…å®¹é•¿åº¦: {len(report_content)} å­—ç¬¦")
                
                # åå¤„ç†ï¼šå°†æ¨èé˜…è¯»ä¸­çš„æ–‡ç« æ ‡é¢˜æ›¿æ¢ä¸ºå®é™…é“¾æ¥
                report_content = self.process_recommended_reading_links(report_content, recommended_articles)
                
            except Exception as api_error:
                print(f"AI APIè°ƒç”¨å¤±è´¥: {api_error}")
                if progress_callback:
                    progress_callback(75, 'AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ...', 'ç”ŸæˆåŸºç¡€å‘¨æŠ¥')
                
                # å¦‚æœAI APIå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿ç”ŸæˆåŸºç¡€å‘¨æŠ¥
                report_content = self.generate_template_report(articles_data)
            
            if progress_callback:
                progress_callback(90, 'æ­£åœ¨åˆ›å»ºå‘¨æŠ¥æ–‡ç« ...', 'æ„å»ºæ–‡ç« æ•°æ®ç»“æ„')
            
            # åˆ›å»ºå‘¨æŠ¥æ–‡ç« æ•°æ®
            report_data = {
                'id': f"weekly-report-{int(time.time())}",
                'title': f"AIå‘¨æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆç¬¬%Uå‘¨')}",
                'source': 'AIå‘¨æŠ¥ç”Ÿæˆå™¨',
                'summary': 'åŸºäºæœ¬å‘¨AIç›¸å…³æ–‡ç« è‡ªåŠ¨ç”Ÿæˆçš„å‘¨æŠ¥ï¼Œæ¶µç›–çƒ­é—¨è¯é¢˜ã€é‡è¦çªç ´å’Œè¶‹åŠ¿åˆ†æã€‚',
                'url': '#',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'tags': ['AIå‘¨æŠ¥', 'è¶‹åŠ¿åˆ†æ', 'è¡Œä¸šåŠ¨æ€', 'è‡ªåŠ¨ç”Ÿæˆ'],
                'content': report_content
            }
            
            if progress_callback:
                progress_callback(95, 'æ­£åœ¨ä¿å­˜å‘¨æŠ¥æ–‡ä»¶...', 'ç”ŸæˆHTMLæ–‡ä»¶')
            
            # ç”ŸæˆHTMLæ–‡ä»¶
            html_path = f"articles/{report_data['id']}.html"
            self.generate_weekly_report_html(report_data, html_path)
            
            return report_data, None
            
        except Exception as e:
            print(f"ç”Ÿæˆå‘¨æŠ¥å¤±è´¥: {e}")
            return None, f"ç”Ÿæˆå‘¨æŠ¥å¤±è´¥: {str(e)}"
    
    def process_recommended_reading_links(self, content, recommended_articles):
        """å¤„ç†æ¨èé˜…è¯»éƒ¨åˆ†çš„é“¾æ¥"""
        try:
            import re
            
            # åˆ›å»ºæ–‡ç« æ ‡é¢˜åˆ°IDçš„æ˜ å°„
            title_to_id = {}
            for article in recommended_articles:
                title_to_id[article['title']] = article['id']
            
            # æŸ¥æ‰¾æ¨èé˜…è¯»éƒ¨åˆ†
            recommended_section_pattern = r'<div class="recommended-reading">(.*?)</div>'
            match = re.search(recommended_section_pattern, content, re.DOTALL)
            
            if match:
                recommended_section = match.group(1)
                
                # å¤„ç†æ¯ä¸ªæ¨èé“¾æ¥
                for title, article_id in title_to_id.items():
                    # æŸ¥æ‰¾åŒ…å«è¯¥æ ‡é¢˜çš„é“¾æ¥
                    link_pattern = rf'<a href="[^"]*">({re.escape(title)})</a>'
                    replacement = f'<a href="../articles/{article_id}.html">{title}</a>'
                    recommended_section = re.sub(link_pattern, replacement, recommended_section)
                
                # æ›¿æ¢æ•´ä¸ªæ¨èé˜…è¯»éƒ¨åˆ†
                new_content = content.replace(match.group(0), f'<div class="recommended-reading">{recommended_section}</div>')
                return new_content
            
            return content
            
        except Exception as e:
            print(f"å¤„ç†æ¨èé˜…è¯»é“¾æ¥å¤±è´¥: {e}")
            return content
    
    def generate_template_report(self, articles_data):
        """ç”Ÿæˆæ¨¡æ¿å‘¨æŠ¥ï¼ˆå½“AI APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        try:
            # è·å–æœ€è¿‘çš„æ–‡ç« 
            recent_articles = articles_data[:5]
            
            # æ„å»ºæ–‡ç« åˆ—è¡¨
            articles_list = ""
            for i, article in enumerate(recent_articles, 1):
                articles_list += f"""
<li><strong>{article.get('title', 'æœªçŸ¥æ ‡é¢˜')}</strong> - {article.get('source', 'æœªçŸ¥æ¥æº')} ({article.get('date', 'æœªçŸ¥æ—¥æœŸ')})</li>"""
            
            # ç”Ÿæˆæ¨¡æ¿å‘¨æŠ¥å†…å®¹
            template_content = f"""
<div class="weekly-report-header">
<h1>ğŸ¤– AIå‘¨æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆç¬¬%Uå‘¨')}</h1>
<p class="report-subtitle">AIå‘¨æŠ¥è¶‹åŠ¿åˆ†æè¡Œä¸šåŠ¨æ€è‡ªåŠ¨ç”Ÿæˆ</p>
</div>

<div class="weekly-overview">
<h2>ğŸ“Š æœ¬å‘¨æ¦‚è§ˆ</h2>
<p>æœ¬å‘¨AIé¢†åŸŸæŒç»­å¿«é€Ÿå‘å±•ï¼Œå¤šä¸ªé‡è¦æŠ€æœ¯çªç ´å’Œåº”ç”¨è½åœ°ã€‚ä»¥ä¸‹æ˜¯åŸºäºæœ¬å‘¨æ”¶é›†çš„{len(articles_data)}ç¯‡æ–‡ç« çš„æ€»ç»“åˆ†æã€‚</p>
</div>

<div class="hot-topics">
<h2>ğŸ”¥ çƒ­é—¨è¯é¢˜</h2>
<p>æœ¬å‘¨æœ€å—å…³æ³¨çš„AIè¯é¢˜åŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>å¤§æ¨¡å‹æŠ€æœ¯</strong>ï¼šç»§ç»­åœ¨æ€§èƒ½å’Œæ•ˆç‡æ–¹é¢å–å¾—çªç ´</li>
<li><strong>AIåº”ç”¨è½åœ°</strong>ï¼šæ›´å¤šè¡Œä¸šå¼€å§‹æ·±åº¦åº”ç”¨AIæŠ€æœ¯</li>
<li><strong>AIå®‰å…¨ä¸ä¼¦ç†</strong>ï¼šç›¸å…³è®¨è®ºå’Œè§„èŒƒåˆ¶å®šæŒç»­æ¨è¿›</li>
</ul>
</div>

<div class="key-breakthroughs">
<h2>ğŸ’¡ é‡è¦çªç ´</h2>
<p>æœ¬å‘¨AIæŠ€æœ¯çš„é‡è¦è¿›å±•ï¼š</p>
<ul>
<li><strong>æ¨¡å‹ä¼˜åŒ–</strong>ï¼šåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬</li>
<li><strong>å¤šæ¨¡æ€èƒ½åŠ›</strong>ï¼šæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å¤„ç†èƒ½åŠ›è¿›ä¸€æ­¥æå‡</li>
<li><strong>æ¨ç†èƒ½åŠ›</strong>ï¼šå¤æ‚é€»è¾‘æ¨ç†å’Œé—®é¢˜è§£å†³èƒ½åŠ›å¢å¼º</li>
</ul>
</div>

<div class="industry-trends">
<h2>ğŸ“ˆ è¡Œä¸šåŠ¨æ€</h2>
<p>AIè¡Œä¸šå‘å±•è¶‹åŠ¿ï¼š</p>
<ul>
<li><strong>ä¼ä¸šåº”ç”¨</strong>ï¼šæ›´å¤šä¼ä¸šå¼€å§‹å°†AIé›†æˆåˆ°ä¸šåŠ¡æµç¨‹ä¸­</li>
<li><strong>å¼€æºç”Ÿæ€</strong>ï¼šå¼€æºAIå·¥å…·å’Œæ¨¡å‹æŒç»­ä¸°å¯Œ</li>
<li><strong>äººæ‰åŸ¹å…»</strong>ï¼šAIç›¸å…³æ•™è‚²å’ŒåŸ¹è®­éœ€æ±‚å¢é•¿</li>
</ul>
</div>

<div class="recommended-reading">
<h2>ğŸ“š æœ¬å‘¨æ¨èæ–‡ç« </h2>
<p>åŸºäºæœ¬å‘¨æ”¶é›†çš„æ–‡ç« ï¼Œæ¨èä»¥ä¸‹å†…å®¹ï¼š</p>
<ul>{articles_list}
</ul>
</div>

<div class="weekly-summary">
<h2>ğŸ¯ æœ¬å‘¨æ€»ç»“</h2>
<p>æœ¬å‘¨AIé¢†åŸŸç»§ç»­ä¿æŒå¿«é€Ÿå‘å±•æ€åŠ¿ï¼ŒæŠ€æœ¯åˆ›æ–°å’Œåº”ç”¨è½åœ°å¹¶é‡ã€‚å»ºè®®æŒç»­å…³æ³¨å¤§æ¨¡å‹æŠ€æœ¯è¿›å±•ã€è¡Œä¸šåº”ç”¨æ¡ˆä¾‹ä»¥åŠç›¸å…³æ”¿ç­–åŠ¨æ€ã€‚</p>
</div>
"""
            return template_content
            
        except Exception as e:
            print(f"ç”Ÿæˆæ¨¡æ¿å‘¨æŠ¥å¤±è´¥: {e}")
            return "<p>å‘¨æŠ¥ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚</p>"
    
    def generate_weekly_report_html(self, article_data, html_path):
        """ç”Ÿæˆå‘¨æŠ¥HTMLæ–‡ä»¶"""
        try:
            # æ„å»ºå‘¨æŠ¥ä¸“ç”¨HTMLå†…å®¹
            html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{article_data['title']} | äº‘ç§’æ­AIå‘¨æŠ¥</title>
    <meta name="description" content="{article_data['title']} - äº‘ç§’æ­AIå‘¨æŠ¥">
    <link rel="stylesheet" href="../styles.css">
    <link rel="icon" type="image/png" href="../favicon.png">
    <link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&display=swap" rel="stylesheet">
</head>
<body>
    <div class="pixel-bg"></div>
    
    <div class="container">
        <main class="article-content">
            {article_data['content']}
        </main>
        
        <div class="article-actions">
            <a href="../index.html" class="action-btn">ğŸ  è¿”å›é¦–é¡µ</a>
            <a href="../admin.html" class="action-btn">âš™ï¸ ç®¡ç†åå°</a>
        </div>
    </div>
</body>
</html>"""
            
            # å†™å…¥æ–‡ä»¶
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            print(f"å‘¨æŠ¥HTMLæ–‡ä»¶ç”ŸæˆæˆåŠŸ: {html_path}")
            return True
            
        except Exception as e:
            print(f"ç”Ÿæˆå‘¨æŠ¥HTMLæ–‡ä»¶å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ PDFæ–‡æ¡£å¤„ç†æ¨¡å—")
    print("=" * 50)
    
    processor = PDFProcessor()
    
    # æµ‹è¯•PDFå¤„ç†
    test_pdf = input("è¯·è¾“å…¥PDFæ–‡ä»¶è·¯å¾„: ").strip()
    
    if not test_pdf or not os.path.exists(test_pdf):
        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„PDFæ–‡ä»¶è·¯å¾„")
        return
    
    # å¤„ç†PDF
    article_data, error = processor.create_article_from_pdf(test_pdf)
    
    if article_data:
        print("\nğŸ“„ æ–‡ç« ä¿¡æ¯:")
        print(f"æ ‡é¢˜: {article_data['title']}")
        print(f"æ¥æº: {article_data['source']}")
        print(f"æ—¥æœŸ: {article_data['date']}")
        print(f"æ ‡ç­¾: {', '.join(article_data['tags'])}")
        print(f"æ‘˜è¦: {article_data['summary'][:100]}...")
        
        # è¯¢é—®æ˜¯å¦æ›´æ–°åˆ°ç½‘ç«™
        confirm = input("\næ˜¯å¦å°†æ­¤æ–‡ç« æ·»åŠ åˆ°ç½‘ç«™? (y/n): ").strip().lower()
        
        if confirm in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
            if processor.update_articles_json(article_data):
                print("\nğŸ‰ æ–‡ç« å·²æˆåŠŸæ·»åŠ åˆ°ç½‘ç«™!")
                print("è¯·åˆ·æ–°æµè§ˆå™¨æŸ¥çœ‹æ›´æ–°åçš„å†…å®¹ã€‚")
            else:
                print("\nâŒ æ·»åŠ æ–‡ç« å¤±è´¥")
        else:
            print("\nâŒ å·²å–æ¶ˆæ·»åŠ ")
    else:
        print(f"\nâŒ å¤„ç†PDFå¤±è´¥: {error}")

if __name__ == "__main__":
    main()
